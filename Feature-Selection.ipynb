{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfc0bc7b",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5b71f",
   "metadata": {},
   "source": [
    "# FILTER METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ec2546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:32:29.940234Z",
     "start_time": "2021-08-08T01:32:29.195745Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#libs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9c4f09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:27:38.715312Z",
     "start_time": "2021-08-08T01:27:38.347313Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b2023719316c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropConstantFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/train_in_data/lib/python3.9/site-packages/feature_engine/selection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mselection\u001b[0m \u001b[0mincludes\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0mto\u001b[0m \u001b[0mselect\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mremove\u001b[0m \u001b[0munwanted\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdrop_constant_features\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropConstantFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdrop_correlated_features\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropCorrelatedFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicate_features\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropDuplicateFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/train_in_data/lib/python3.9/site-packages/feature_engine/selection/drop_constant_features.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe_checks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_contains_na\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_selector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseSelector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_return_tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/train_in_data/lib/python3.9/site-packages/feature_engine/dataframe_checks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_is_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[1;32m     14\u001b[0m     \u001b[0mChecks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'DataFrame'"
     ]
    }
   ],
   "source": [
    "from feature_engine.selection import DropConstantFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f96a421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:34:09.203382Z",
     "start_time": "2021-08-08T01:32:55.810590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.1\n",
      "  latest version: 4.10.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/daianeklein/opt/anaconda3/envs/train_in_data\n",
      "\n",
      "  removed specs:\n",
      "    - feature_engine\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ipython-7.26.0             |   py39h01d92e1_0         996 KB\n",
      "    jedi-0.18.0                |   py39hecd8cb5_1         909 KB\n",
      "    matplotlib-inline-0.1.2    |     pyhd3eb1b0_2          12 KB\n",
      "    notebook-6.4.1             |   py39hecd8cb5_0         4.1 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  matplotlib-inline  pkgs/main/noarch::matplotlib-inline-0.1.2-pyhd3eb1b0_2\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  feature_engine-1.1.1-pyhd8ed1ab_0\n",
      "  joblib-1.0.1-pyhd8ed1ab_0\n",
      "  libgfortran-3.0.1-0\n",
      "  llvm-openmp-12.0.1-hda6cdc1_1\n",
      "  patsy-0.5.1-py_0\n",
      "  python_abi-3.9-2_cp39\n",
      "  scikit-learn-0.24.2-py39hb2f4e1b_0\n",
      "  scipy-1.6.2-py39hd5f7400_1\n",
      "  statsmodels-0.12.2-py39h329c335_0\n",
      "  threadpoolctl-2.2.0-pyh8a188c0_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ipython                             7.22.0-py39h01d92e1_0 --> 7.26.0-py39h01d92e1_0\n",
      "  jedi                                0.17.2-py39hecd8cb5_1 --> 0.18.0-py39hecd8cb5_1\n",
      "  notebook                             6.4.0-py39hecd8cb5_0 --> 6.4.1-py39hecd8cb5_0\n",
      "  parso                                          0.7.0-py_0 --> 0.8.2-pyhd3eb1b0_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  mkl-service        conda-forge::mkl-service-2.4.0-py39h8~ --> pkgs/main::mkl-service-2.4.0-py39h9ed2024_0\n",
      "  pytz                conda-forge::pytz-2021.1-pyhd8ed1ab_0 --> pkgs/main::pytz-2021.1-pyhd3eb1b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "matplotlib-inline-0. | 12 KB     | ##################################### | 100% \n",
      "notebook-6.4.1       | 4.1 MB    | ##################################### | 100% \n",
      "jedi-0.18.0          | 909 KB    | ##################################### | 100% \n",
      "ipython-7.26.0       | 996 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda uninstall feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf42cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b77d27e",
   "metadata": {},
   "source": [
    "## REMOVING CONSTANT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2865d26a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:32:32.678349Z",
     "start_time": "2021-08-08T01:32:32.306626Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c119f9734b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset_1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read_csv'"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('dataset_1.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a544bd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:22:44.168852Z",
     "start_time": "2021-08-08T01:22:44.157268Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1915fbb7ef2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ab72e",
   "metadata": {},
   "source": [
    "In all feature selection procedures, it is good practice to select the features by examining only the training set. And this is to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db9e2524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:22:44.480079Z",
     "start_time": "2021-08-08T01:22:44.467547Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1b4caee081bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     random_state = 0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1.drop(labels=['target'], axis = 1),\n",
    "    df1['target'],\n",
    "    test_size = 0.3,\n",
    "    random_state = 0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41645e82",
   "metadata": {},
   "source": [
    "## Using VarianceThreshold from Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df88a525",
   "metadata": {},
   "source": [
    "The VarianceThreshold from sklearn provides a simple baseline approach to feature selection. It removes all features which variance doesn’t meet a certain threshold. By default, it removes all zero-variance features, i.e., features that have the same value in all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc8e68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:47.985546Z",
     "start_time": "2021-08-08T01:11:46.093Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold = 0)\n",
    "sel.fit(X_train) #fit finds the features with zero variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1423ec",
   "metadata": {},
   "source": [
    "If we sum over get_support, we get the number of features that are not constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afddd99b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:47.987412Z",
     "start_time": "2021-08-08T01:11:46.097Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e87052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:47.991719Z",
     "start_time": "2021-08-08T01:11:46.100Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape[1] - sum(sel.get_support()) #constante features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d76de21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:47.995418Z",
     "start_time": "2021-08-08T01:11:46.103Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting constant variables names\n",
    "constant = X_train.columns[~sel.get_support()]\n",
    "constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd3808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:47.997124Z",
     "start_time": "2021-08-08T01:11:46.107Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking\n",
    "for c in constant:\n",
    "    print(c, X_train[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b84a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:47.999390Z",
     "start_time": "2021-08-08T01:11:46.110Z"
    }
   },
   "outputs": [],
   "source": [
    "# non-constant feature names\n",
    "non_const = X_train.columns[sel.get_support()]\n",
    "non_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7dd278",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.001904Z",
     "start_time": "2021-08-08T01:11:46.113Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47cc7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.004440Z",
     "start_time": "2021-08-08T01:11:46.117Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataframe\n",
    "X_train = pd.DataFrame(X_train, columns = non_const)\n",
    "X_train.sample(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6603707",
   "metadata": {},
   "source": [
    "## STD from PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086c5e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.006356Z",
     "start_time": "2021-08-08T01:11:46.121Z"
    }
   },
   "outputs": [],
   "source": [
    "#train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1.drop(labels=['target'], axis=1),\n",
    "    df1['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317977e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.008720Z",
     "start_time": "2021-08-08T01:11:46.124Z"
    }
   },
   "outputs": [],
   "source": [
    "# std \n",
    "const_features = [f for f in X_train.columns if X_train[f].std() == 0]\n",
    "\n",
    "# len\n",
    "len(const_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedaaeba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.010966Z",
     "start_time": "2021-08-08T01:11:46.129Z"
    }
   },
   "outputs": [],
   "source": [
    "# drops these variables from our datasets\n",
    "X_train = X_train.drop(labels = const_features, axis = 1)\n",
    "X_test = X_test.drop(labels = const_features, axis = 1)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc496a4",
   "metadata": {},
   "source": [
    "## MANUAL CODE - CATEGORICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f38f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.013377Z",
     "start_time": "2021-08-08T01:11:46.134Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1.drop(labels=['target'], axis=1),\n",
    "    df1['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d34bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.015734Z",
     "start_time": "2021-08-08T01:11:46.138Z"
    }
   },
   "outputs": [],
   "source": [
    "# all features to object\n",
    "X_train = X_train.astype('O')\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac4cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.018010Z",
     "start_time": "2021-08-08T01:11:46.142Z"
    }
   },
   "outputs": [],
   "source": [
    "#using nunique from pandas\n",
    "const_features = [f for f in X_train.columns if X_train[f].nunique() == 1]\n",
    "\n",
    "len(const_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1140b76d",
   "metadata": {},
   "source": [
    "Note by default nunique() ignores missing values, so if your variables have missing values, use dropna=False within the parameters of nunique()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2366f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.020220Z",
     "start_time": "2021-08-08T01:11:46.146Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.drop(labels=const_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=const_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea94a8",
   "metadata": {},
   "source": [
    "# Quasi-constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a671494",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.022538Z",
     "start_time": "2021-08-08T01:11:46.150Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ef3d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.024370Z",
     "start_time": "2021-08-08T01:11:46.153Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1.drop(labels=['target'], axis = 1),\n",
    "    df1['target'],\n",
    "    test_size = 0.3,\n",
    "    random_state = 0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c3d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.027333Z",
     "start_time": "2021-08-08T01:11:46.156Z"
    }
   },
   "outputs": [],
   "source": [
    "#first, remove constant features\n",
    "\n",
    "const_features = [feat for feat in X_train.columns if X_train[feat].std() == 0]\n",
    "\n",
    "X_train.drop(labels = const_features, axis = 1, inplace = True)\n",
    "X_test.drop(labels = const_features, axis = 1, inplace = True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc829ec3",
   "metadata": {},
   "source": [
    "## Remove quasi-constant features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1fa662",
   "metadata": {},
   "source": [
    "By default, VarianceThreshold from sklearn removes all zero-variance features.\n",
    "\n",
    "Here, we will change the default threshold to remove quasi-constant features - features with low-variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeccf88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.029614Z",
     "start_time": "2021-08-08T01:11:46.160Z"
    }
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold = 0.01)\n",
    "sel.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78833447",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.031454Z",
     "start_time": "2021-08-08T01:11:46.163Z"
    }
   },
   "outputs": [],
   "source": [
    "# variance > 0\n",
    "sum(sel.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55687c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.033763Z",
     "start_time": "2021-08-08T01:11:46.167Z"
    }
   },
   "outputs": [],
   "source": [
    "# variance < 0\n",
    "quasi_const = X_train.columns[~sel.get_support()]\n",
    "len(quasi_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492996cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.036640Z",
     "start_time": "2021-08-08T01:11:46.170Z"
    }
   },
   "outputs": [],
   "source": [
    "# columns \n",
    "quasi_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc95c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.038931Z",
     "start_time": "2021-08-08T01:11:46.173Z"
    }
   },
   "outputs": [],
   "source": [
    "# example var_1\n",
    "X_train['var_1'].value_counts() / np.float64(len(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fafa97b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.040797Z",
     "start_time": "2021-08-08T01:11:46.179Z"
    }
   },
   "outputs": [],
   "source": [
    "# features names\n",
    "feat_names = X_train.columns[sel.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70e1e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.042703Z",
     "start_time": "2021-08-08T01:11:46.183Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove the quasi-constant features\n",
    "X_train = sel.transform(X_train)\n",
    "X_test = sel.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7111b99c",
   "metadata": {},
   "source": [
    "By removing constant and almost constant features, we reduced the feature space from 300 to 215. This means, that 85 features were removed from this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dde2cd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.044822Z",
     "start_time": "2021-08-08T01:11:46.189Z"
    }
   },
   "outputs": [],
   "source": [
    "# trasnform the array into a dataframe\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=feat_names)\n",
    "X_test = pd.DataFrame(X_test, columns=feat_names)\n",
    "\n",
    "X_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b6577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-07T23:44:53.923562Z",
     "start_time": "2021-08-07T23:44:53.911848Z"
    }
   },
   "source": [
    "### Coding it ourselves\n",
    "\n",
    "This method, as opposed to the VarianceThreshold, can be used for both **numerical and categorical** variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639508cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.046582Z",
     "start_time": "2021-08-08T01:11:46.194Z"
    }
   },
   "outputs": [],
   "source": [
    "# separate train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1.drop(labels=['target'], axis=1),\n",
    "    df1['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "# remove constant features\n",
    "# using the code from the previous lecture\n",
    "\n",
    "constant_features = [\n",
    "    feat for feat in X_train.columns if X_train[feat].std() == 0\n",
    "]\n",
    "\n",
    "X_train.drop(labels=constant_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=constant_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aea46c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.049507Z",
     "start_time": "2021-08-08T01:11:46.198Z"
    }
   },
   "outputs": [],
   "source": [
    "# create an empty list\n",
    "quasi_constant_feat = []\n",
    "\n",
    "# iterate over every feature\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # find the predominant value, that is the value that is shared\n",
    "    # by most observations\n",
    "    predominant = (X_train[feature].value_counts() / np.float64(\n",
    "        len(X_train))).sort_values(ascending=False).values[0]\n",
    "    \n",
    "    if predominant > 0.998:\n",
    "        quasi_constant_feat.append(feature)\n",
    "        \n",
    "len(quasi_constant_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05019fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.052338Z",
     "start_time": "2021-08-08T01:11:46.203Z"
    }
   },
   "outputs": [],
   "source": [
    "# features names\n",
    "quasi_constant_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27789504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.054466Z",
     "start_time": "2021-08-08T01:11:46.207Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking\n",
    "X_train['var_3'].value_counts() / np.float64(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d899c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.058399Z",
     "start_time": "2021-08-08T01:11:46.211Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f7aa0",
   "metadata": {},
   "source": [
    "# DUPLICATED FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4701f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.060377Z",
     "start_time": "2021-08-08T01:11:46.215Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking null values\n",
    "[col for col in df1.columns if df1[col].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0b782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.062121Z",
     "start_time": "2021-08-08T01:11:46.218Z"
    }
   },
   "outputs": [],
   "source": [
    "# separate dataset into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df1.drop(labels=['target'], axis=1), # drop the target\n",
    "    df1['target'], # just the target\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eacf291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.063733Z",
     "start_time": "2021-08-08T01:11:46.222Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove constant and quasi-constant features first\n",
    "quasi_constant_feat = []\n",
    "\n",
    "# iterate over every feature\n",
    "for feature in X_train.columns:\n",
    "\n",
    "    # find the predominant value, that is the value that is shared\n",
    "    # by most observations\n",
    "    predominant = (X_train[feature].value_counts() / np.float64(\n",
    "        len(X_train))).sort_values(ascending=False).values[0]\n",
    "\n",
    "    # evaluate predominant feature: do more than 99% of the observations\n",
    "    # show 1 value?\n",
    "    if predominant > 0.998:\n",
    "        quasi_constant_feat.append(feature)\n",
    "\n",
    "len(quasi_constant_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24cf98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.065652Z",
     "start_time": "2021-08-08T01:11:46.225Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop these columns from dataset\n",
    "X_train.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "X_test.drop(labels=quasi_constant_feat, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f079230f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.067334Z",
     "start_time": "2021-08-08T01:11:46.228Z"
    }
   },
   "outputs": [],
   "source": [
    "# check for duplicated features in the training set:\n",
    "\n",
    "#empty dictionary\n",
    "duplicated_feat_pairs = {}\n",
    "\n",
    "# create an empty list to collect features\n",
    "# that were found to be duplicated\n",
    "_duplicated_feat = []\n",
    "\n",
    "\n",
    "# iterate over every feature in our dataset:\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    \n",
    "    # this bit helps me understand where the loop is at:\n",
    "    if i % 10 == 0:  \n",
    "        print(i)\n",
    "    \n",
    "    # choose 1 feature:\n",
    "    feat_1 = X_train.columns[i]\n",
    "    \n",
    "    # check if this feature has already been identified\n",
    "    # as a duplicate of another one. If it was, it should be stored in\n",
    "    # our _duplicated_feat list.\n",
    "    \n",
    "    # If this feature was already identified as a duplicate, we skip it, if\n",
    "    # it has not yet been identified as a duplicate, then we proceed:\n",
    "    if feat_1 not in _duplicated_feat:\n",
    "    \n",
    "        # create an empty list as an entry for this feature in the dictionary:\n",
    "        duplicated_feat_pairs[feat_1] = []\n",
    "\n",
    "        # now, iterate over the remaining features of the dataset:\n",
    "        for feat_2 in X_train.columns[i + 1:]:\n",
    "\n",
    "            # check if this second feature is identical to the first one\n",
    "            if X_train[feat_1].equals(X_train[feat_2]):\n",
    "\n",
    "                # if it is identical, append it to the list in the dictionary\n",
    "                duplicated_feat_pairs[feat_1].append(feat_2)\n",
    "                \n",
    "                # and append it to our monitor list for duplicated variables\n",
    "                _duplicated_feat.append(feat_2)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d41bed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.069446Z",
     "start_time": "2021-08-08T01:11:46.232Z"
    }
   },
   "outputs": [],
   "source": [
    "#list of duplicated features\n",
    "len(_duplicated_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499aacea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.073225Z",
     "start_time": "2021-08-08T01:11:46.235Z"
    }
   },
   "outputs": [],
   "source": [
    "_duplicated_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8e13a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.074857Z",
     "start_time": "2021-08-08T01:11:46.240Z"
    }
   },
   "outputs": [],
   "source": [
    "duplicated_feat_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd91e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.076118Z",
     "start_time": "2021-08-08T01:11:46.244Z"
    }
   },
   "outputs": [],
   "source": [
    "# print the features with its duplicates\n",
    "\n",
    "# iterate over every feature in our dict:\n",
    "for feat in duplicated_feat_pairs.keys():\n",
    "    \n",
    "    # if it has duplicates, the list should not be empty:\n",
    "    if len(duplicated_feat_pairs[feat]) > 0:\n",
    "\n",
    "        # print the feature and its duplicates:\n",
    "        print(feat, duplicated_feat_pairs[feat])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1721e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.077672Z",
     "start_time": "2021-08-08T01:11:46.248Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[X_train['var_37'] != 0][['var_37', 'var_148']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb6238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-08T01:11:48.078963Z",
     "start_time": "2021-08-08T01:11:46.251Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train[duplicated_feat_pairs.keys()]\n",
    "X_test = X_test[duplicated_feat_pairs.keys()]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1229ee4c",
   "metadata": {},
   "source": [
    "# Constant and Quasi-constant features with Feature-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9bff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_in_data",
   "language": "python",
   "name": "train_in_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
